{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjP+B90bHGgAueF1m/Ug24"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T-mFSqqekkTx"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/Colab Notebooks\")\n","from multiclass_functions2_8 import * # all\n","import torch\n","from torch import nn, optim\n","from torchvision import datasets, transforms\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","import matplotlib.pyplot as plt\n","import copy\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(DEVICE)"]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","LR = 2e-3\n","LR_STEP = 3\n","LR_GAMMA = 0.9\n","EPOCH = 10\n","TRAIN_RATIO = 0.8\n","criterion = nn.CrossEntropyLoss()\n","new_model_train = False\n","model_type = \"CNN_deep\"\n","dataset = \"STL10\"\n","save_model_path = f\"/content/drive/MyDrive/Colab Notebooks/results/{model_type}_{dataset}.pt\"\n","save_history_path = f\"/content/drive/MyDrive/Colab Notebooks/results/{model_type}_history_{dataset}.pt\""],"metadata":{"id":"vwQT-99Vkr6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def to_uint8(x):\n","    return (255*x).type(torch.uint8)"],"metadata":{"id":"dQO6JVV_ks38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform_train = transforms.Compose([\n","    transforms.ToTensor(),\n","\n","    # transforms.Lambda(to_uint8),\n","    # to_uint8,\n","    # transforms.Lambda(lambda x:(255*x).type(torch.uint8)),\n","    # lambda x:(255*x).type(torch.uint8),\n","    # 위쪽 4개 모두 가능\n","\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    # (아마도) 이미지넷 데이터 전체 픽셀에 대해서 구한 평균, std 값\n","    # normalize후 imshow시 이미지가 이상하게 나오는데, 그 이유는 음의 값을 처리하지 못 하기 떄문. 값은 문제 없다.\n","    # 이를 방지하기 위해 이미지에 이미지의 최솟값(음수)를 빼주고 max값을 나눠준다. -> im_plot 함수에 구현되어 있음.\n","\n","    # transforms.Resize(size=(20,20)), # size는 (height,width)\n","    # transforms.CenterCrop(size=(20,20)), # size 는 (height, width)\n","    # transforms.Pad(6), # 20+6*2 = 32\n","    # transforms.RandomApply(nn.ModuleList([transforms.CenterCrop(size=(20,20)), # random하게 apply\n","    #                                       transforms.Pad(6)]), p=0.5), # ModuleList 안해도 되더라\n","    # transforms.RandomCrop(size=(20,20)), # 어디를 자를지 random 하게 자름\n","    # transforms.RandomResizedCrop(size=(20,20), scale=(0.3,1), ratio=(0.3,1.7)),\n","    # random 하게 자른 다음에 resize라서 RandomCrop과 다름\n","    # scale은 어느 정도로 작은 범위를 자를지 (0~1 사이 값)\n","    # ratio는 aspect ratio로, 가로 길이/세로 길이 를 의미한다.\n","    # (a,b) <- a 와 b 사이 값을 uniform random 하게 뽑아요\n","\n","    # transforms.RandomGrayscale(p=0.5), # gray로 바꾸는 데, 출력 채널 수를 3으로 유지\n","    # transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.5, hue=0.15),\n","    # 밝기, 대비, 채도, 색조가 센서마다 다를 수 있음을 고려 (number: percentage to convert)\n","    # 자율주행 자동차에서 a 카메라, b 카메라가 위와 같은 요소들이 달라질 수 있음.\n","    # 밝기(brightness)를 키우면 밝은 부분에서 saturation이 일어나면서, HDR이 낮은 센서에 대응 가능\n","    # 대비(contrast) augmentation은 HDR이 서로 다른 센서에 대응 가능\n","    # 채도(saturation) 및 색조(hue) augmentation은 ISP에서 color correction matrix 값이 센서마다 서로 다른 경우 등,\n","    # 색 표현이 다른 센서에 대응 가능\n","    # transforms.RandomAutocontrast(p=0.5), # p의 확률로 대비를 자동 조정\n","    # transforms.RandomEqualize(p=0.5), # p의 확률로 R,G,B histogram을 일치시킴 (이건 uint8로 되어있는 이미지만 가능)\n","    # transforms.RandomInvert(p=0.5), # p의 확률로 색반전\n","    # new 픽셀 값 = 최댓 값 - 기존의 픽셀 값 을 통해 반전시킴\n","    # transforms.RandomSolarize(threshold=200, p=0.5),\n","    # p의 확률로(즉 그 이미지에 대해 할지 말지 정하고) threshold 넘는 픽셀 값에 대해 inverting\n","    # transforms.RandomPosterize(bits=3, p=0.5),\n","    # 픽셀 하나가 가지는 값의 bit수(0~8)를 p의 확률로 bits로 바꿈 (이건 uint8로 되어있는 것만 가능)\n","\n","    # transforms.GaussianBlur(kernel_size=(5,5), sigma=(0.1,2)),\n","    # kernel_size = (가로,세로) sigma=(min,max) min ~ max 에서 uniform 하게 하나 뽑음\n","    # transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n","    # sharpness_factor = 1 이면 원래 이미지, 0에 가까우면 blur, 1보다 클수록 sharp해짐\n","\n","    # transforms.RandomHorizontalFlip(p=0.4), # p 확률로 좌우반전\n","    # transforms.RandomVerticalFlip(p=0.5), # p 확률로 상하반전\n","    # transforms.RandomRotation(degrees=(0,180)), # 0~180도 랜덤하게 회전\n","    # transforms.RandomAffine(degrees=(0,30),translate=(0.1,0.3),scale=(0.5,1.2)),\n","    # translate는 이동하는 정도 (비율), scale은 크기 조절\n","    # transforms.RandomPerspective(distortion_scale=0.6, p=0.5), # distortion 정도 0~1 사이, default는 0.5, p는 적용 확률\n","\n","    # transforms.RandomErasing(p=0.5, scale=(0.03,0.3), ratio=(0.3,3.3)),\n","    # scale: 이미지의 몇 퍼 정도를 지울지\n","    # ratio: 지우는 영역의 aspect ratio\n","\n","    # transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n","    # transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n","    # transforms.AutoAugment(transforms.AutoAugmentPolicy.SVHN),\n","    # AutoAugment:Learning Augmentation Strategies from Data 라는 논문에 따른 augmentation (uint8 이여야 함)\n","    # transforms.RandAugment(),\n","    # RandAugment: Practical automated data augmentation with a reduced search space 라는 논문에 따른 augmentation (uint8 이여야 함)\n","    # transforms.TrivialAugmentWide(),\n","    # TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation 라는 논문에 따른 augmentation (uint8)\n","    # transforms.AugMix(),\n","    # AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty 라는 논문에 따른 augmentaiton (uint8)\n","    ])\n","transform_test = transforms.ToTensor()"],"metadata":{"id":"qn_onCBeks8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_DS = datasets.CIFAR10(root = '/content/drive/MyDrive/Colab Notebooks/data', train=True, download=True, transform=transform_train)\n","NoT = int(len(train_DS)*TRAIN_RATIO); NoV = len(train_DS) - NoT\n","train_DS, val_DS = torch.utils.data.random_split(train_DS, [NoT, NoV])\n","val_DS.transform = transform_test\n","test_DS = datasets.CIFAR10(root = '/content/drive/MyDrive/Colab Notebooks/data', train=False, download=True, transform=transform_test)\n","\n","train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n","val_DL = torch.utils.data.DataLoader(val_DS, batch_size=BATCH_SIZE, shuffle=False)\n","test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"mAjk6mjZks-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Albumentation 쓸 때만 주석 해제\n","# Object detection augmentation도 할 수 있음. -> gt값을 자동으로 바꿔 줌.\n","\n","transform_train = A.Compose([\n","    A.Resize(20,20),\n","    A.HorizontalFlip(p=0.5),\n","    A.VerticalFlip(p=0.5),\n","\n","    A.ShiftScaleRotate(shift_limit=(-0.05,0.05), scale_limit=(0,0), rotate_limit=(-10,10), p=0.7, border_mode=cv2.BORDER_CONSTANT),\n","    A.RandomResizedCrop(height=20, width=20, scale=(0.3, 1), ratio=(0.75, 1.33), p=0.7),\n","\n","    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.8),\n","\n","    A.OneOf([\n","             A.ElasticTransform(p=1, sigma=30, alpha=10, alpha_affine=5),\n","             #  sigma는 간격, alpha는 꼬불한 정도, alpla_affine은 affine transform의 정도\n","             A.GridDistortion(p=1), # grid로 쪼갠다음 각 patch들을 짜부시킴\n","             A.OpticalDistortion(p=1,distort_limit=1, shift_limit=0.5),\n","             #  distort_limit 가운데 부분이 볼록 튀어나와 보이는 정도 (0~1), shift_limit은 어느정도 이미지를 밀건지 (0~1)\n","             ], p=1),\n","\n","    # A.Normalize(), # 애는 default가 0~255인 이미지가 들어오는 것으로 되어있어서 normalize 먼저\n","    ToTensorV2()])\n","\n","transform_test = ToTensorV2() # unit8, 0~255는 그대로, Tensor, 개채행열로만 바꿔줌\n","\n","# Albumentation 쓰려면 다음과 같이 오버라이딩 해야 한다.\n","class CIFAR10_custom(datasets.CIFAR10):\n","    def __init__(self, root=\"/content/drive/MyDrive/Colab Notebooks/data\", train=True, download=True, transform=None):\n","        super().__init__(root=root, train=train, download=download, transform=transform)\n","\n","    def __getitem__(self, index):\n","        image = self.data[index]\n","        label = self.targets[index]\n","\n","        if self.transform is not None:\n","            transformed = self.transform(image=image) # self.transform(image=image, mask=mask)\n","            image = transformed[\"image\"]\n","            # mask = transformed[\"mask\"]\n","\n","        return image, label\n","\n","test_DS = CIFAR10_custom(root = '/content/drive/MyDrive/Colab Notebooks/data', train=False, download=True, transform=transform_test)\n","test_DL = torch.utils.data.DataLoader(test_DS, batch_size = BATCH_SIZE, shuffle = False)"],"metadata":{"id":"MmwzrLXcktBI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_DS_wT = copy.deepcopy(test_DS) # wT = with Transform\n","test_DS_wT.transform = transform_train\n","test_DL_wT = torch.utils.data.DataLoader(test_DS_wT, batch_size = BATCH_SIZE, shuffle = False)\n","\n","im_plot(test_DL)\n","im_plot(test_DL_wT)"],"metadata":{"id":"5FXQFIdCkyIP"},"execution_count":null,"outputs":[]}]}