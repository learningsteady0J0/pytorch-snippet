{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP05HKWX7cnaYZG1d+wcGqh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RsNYuBDF4FS3"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torchvision import transforms, datasets\n","from torchvision.ops import StochasticDepth\n","import math"]},{"cell_type":"code","source":["# stochastic depth 에 대해\n","class test_model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.residual = nn.Conv2d(1,1,1, bias=False)\n","        self.stochastic_depth = StochasticDepth(0.3, \"row\") # 0.3이 죽일 확률 # \"row\"는 data 마다 다른 depth를 가지게 함!\n","\n","    def forward(self,x):\n","        residual = self.residual(x)\n","        residual = self.stochastic_depth(residual)\n","        return x + residual\n","\n","model=test_model()\n","x=torch.ones(2,1,2,2)\n","model.train()\n","print(model(x)) # 훈련 때는 1/(1-p) 을 residual에 곱한다\n","w=model.residual.weight.item()\n","print(round(1 + 1 * w/(1-0.3), 4))\n","\n","model.eval()\n","print(model(x))\n","print(round(1 + 1 * w, 4)) # 테스트는 무시하지 않고 통과시킨다.\n","# stochastic depth는 드랍아웃을 node가 아닌 residual에 적용했다고 생각할 수 있다. (residual=0 이면 그냥 통과인거니까)\n","# stochastic depth 논문에서는 훈련 때는 랜덤하게 skip하고 테스트 때는 다 통과하되 1-p를 곱하는 것으로 설명 되어있다.\n","# 하지만 토치 구현에서는 반대로 train 땐 1/(1-p) 를 곱하고 테스트 때는 그냥 통과하는 것으로 구현!\n","# 드랍아웃도 이처럼 논문과 달리 train 땐 1/(1-p) 로 키워놓고 테스트 때는 그대로 나오게끔 구현되어있음"],"metadata":{"id":"kk5GQRtj4G_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _make_divisible(v, divisor, min_value=None):\n","    \"\"\"\n","    This function is taken from the original tf repo.\n","    It ensures that all layers have a channel number that is divisible by 8\n","    It can be seen here:\n","    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n","    :param v:\n","    :param divisor:\n","    :param min_value:\n","    :return:\n","    \"\"\"\n","    # 쉽게 말해, 이 함수는 가까운 8의 배수를 찾아줌\n","\n","    if min_value is None:\n","        min_value = divisor\n","    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor) # divisor / 2 는 반올림을 위해 (너무 작아지지 않게)\n","    # case 1) v=10, divisor = 8 이면  10+4 // 8 * 8 = 8 근데 10 => 8 은 10% 이상 빠지는 거니까 8+8 = 16 으로 조정됨\n","    # case 2) v=39, divisor = 8 이면 39+4 // 8 * 8 = 40 => 10%보다 빠지지 않았기 때문에 40이 출력됨!\n","\n","    if new_v < 0.9 * v: # 10% 보다 더 빠지지 않게 조정\n","        new_v += divisor\n","\n","    return new_v\n","\n","class SEBlock(nn.Module):\n","    def __init__(self, in_channels, squeeze_channels): # efficientNet 에서도 reduction ratio r=4인 것 같다. (논문에는 딱히 명시되어 있진 않음)\n","        super().__init__()\n","        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n","        self.excitation = nn.Sequential(nn.Linear(in_channels, squeeze_channels),\n","                                        nn.SiLU(inplace=True), # 여기도 SiLU 사용\n","                                        nn.Linear(squeeze_channels, in_channels),\n","                                        nn.Sigmoid())\n","\n","    def forward(self, x):\n","        SE = self.squeeze(x)\n","        SE = SE.reshape(x.shape[0],x.shape[1])\n","        SE = self.excitation(SE)\n","        SE = SE.unsqueeze(dim=2).unsqueeze(dim=3)\n","        x = x * SE\n","        return x\n","\n","class DepSESep(nn.Module):\n","    def __init__(self, in_channels, squeeze_channels, out_channels, kernel_size, stride):\n","        super().__init__()\n","\n","        self.depthwise = nn.Sequential(nn.Conv2d(in_channels, in_channels, kernel_size, stride = stride, padding = (kernel_size - 1) // 2, groups = in_channels, bias=False),\n","                                       nn.BatchNorm2d(in_channels, momentum=0.99, eps=1e-3),\n","                                       nn.SiLU(inplace=True))\n","\n","        self.seblock = SEBlock(in_channels, squeeze_channels)\n","\n","        self.pointwise = nn.Sequential(nn.Conv2d(in_channels, out_channels, 1, bias=False),\n","                                       nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3))\n","                                       # no activation!!\n","    def forward(self, x):\n","        x = self.depthwise(x)\n","        if self.seblock is not None:\n","            x = self.seblock(x)\n","        x = self.pointwise(x)\n","        return x\n","\n","class MBConv(nn.Module):\n","    def __init__(self, in_channels, exp_channels, out_channels, kernel_size, stride, sd_prob):\n","        super().__init__()\n","\n","        self.use_skip_connect = (stride==1 and in_channels==out_channels)\n","        self.stochastic_depth = StochasticDepth(sd_prob, \"row\") # sd_prob가 죽일 확률 # \"row\"는 data 마다 다른 depth를 가지게 함!\n","\n","        layers = []\n","        if in_channels != exp_channels:\n","            layers += [nn.Sequential(nn.Conv2d(in_channels, exp_channels, 1, bias=False),\n","                                     nn.BatchNorm2d(exp_channels, momentum=0.99, eps=1e-3),\n","                                     nn.SiLU(inplace=True))]\n","        squeeze_channels = in_channels // 4\n","        # torchvision.models를 보면 mobilenet v3 에선 squeeze_channels = expanded_channels // 4 로 https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv3.py#L96\n","        # efficientNet 에선 squeeze_channels = in_channels // 4 로 해놨다.. https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py#L149\n","        # 그리고, squeeze_channels에 대해서 make_divisible을 mobilenet v3 에서는 하고 efficientNet에는 안해놓음\n","        layers += [DepSESep(exp_channels, squeeze_channels, out_channels, kernel_size, stride=stride)]\n","\n","        self.residual = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        if self.use_skip_connect:\n","            residual = self.residual(x)\n","            residual = self.stochastic_depth(residual)\n","            return x + residual\n","        else:\n","            return self.residual(x)\n","\n","class EfficientNet(nn.Module):\n","    def __init__(self, num_classes, depth_mult, width_mult, resize_size, crop_size, drop_p, stochastic_depth_p = 0.2):\n","        super().__init__()\n","\n","        cfgs = [#k,  t,   c,  n,  s\n","                [3,  1,  16,  1,  1],\n","                [3,  6,  24,  2,  2],\n","                [5,  6,  40,  2,  2],\n","                [3,  6,  80,  3,  2],\n","                [5,  6,  112, 3,  1],\n","                [5,  6,  192, 4,  2],\n","                [3,  6,  320, 1,  1]]\n","\n","        in_channels = _make_divisible(32 * width_mult, 8) # width 조절!\n","\n","        self.transforms = transforms.Compose([transforms.Resize(resize_size, interpolation=transforms.InterpolationMode.BICUBIC),\n","                                              transforms.CenterCrop(crop_size),\n","                                              transforms.ToTensor(),\n","                                              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) # resolution 조절!\n","\n","        # building first layer\n","        self.stem_conv = nn.Sequential(nn.Conv2d(3, in_channels, 3, padding=1, stride=2, bias=False),\n","                                       nn.BatchNorm2d(in_channels, momentum=0.99, eps=1e-3),\n","                                       nn.SiLU(inplace=True))\n","\n","        # building inverted residual blocks\n","        layers = []\n","        num_block = 0\n","        N = sum([math.ceil(cfg[-2] * depth_mult) for cfg in cfgs]) # 총 깊이\n","        for k, t, c, n, s in cfgs:\n","            n = math.ceil(n * depth_mult) # depth 조절!\n","            for i in range(n):\n","                stride = s if i == 0 else 1\n","                exp_channels = _make_divisible(in_channels * t, 8)\n","                out_channels = _make_divisible(c * width_mult, 8) # width 조절!\n","                sd_prob = stochastic_depth_p * num_block / (N-1) # 앞에는 안뛰고 뒤로 갈수록 건너 뛸 확률을 크게\n","                layers += [MBConv(in_channels, exp_channels, out_channels, k, stride, sd_prob)]\n","                in_channels = out_channels\n","                num_block += 1\n","\n","        self.layers = nn.Sequential(*layers)\n","\n","        # building last several layers\n","        last_channels = _make_divisible(1280 * width_mult, 8) # width 조절!\n","        self.last_conv = nn.Sequential(nn.Conv2d(in_channels, last_channels, 1, bias=False),\n","                                       nn.BatchNorm2d(last_channels, momentum=0.99, eps=1e-3),\n","                                       nn.SiLU(inplace=True))\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        self.classifier = nn.Sequential(nn.Dropout(drop_p), # 논문에는 상세히 나와있진 않지만 토치 문서에 있어서 포함 -> 채널 축으로 특징들이 놓여있고 그것들을 이리저리 바꿔 골라가며 학습하는 의미\n","                                        nn.Linear(last_channels, num_classes))\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","            elif isinstance(m, nn.Linear):\n","                init_range = 1.0 / torch.sqrt(torch.tensor(m.out_features))\n","                nn.init.uniform_(m.weight, -init_range, init_range)\n","                nn.init.zeros_(m.bias)\n","\n","    def forward(self, x):\n","        x = self.stem_conv(x)\n","        x = self.layers(x)\n","        x = self.last_conv(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"lXH1Mbv44HCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://github.com/pytorch/vision/blob/main/torchvision/models/efficientnet.py#L439 참고\n","\n","def efficientnet_b0(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=1.0, width_mult=1.0, resize_size=256, crop_size=224, drop_p=0.2, **kwargs)\n","\n","def efficientnet_b1(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=1.1, width_mult=1.0, resize_size=256, crop_size=240, drop_p=0.2, **kwargs)\n","\n","def efficientnet_b2(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=1.2, width_mult=1.1, resize_size=288, crop_size=288, drop_p=0.3, **kwargs)\n","# torchvision에는 288로 되어있는데, 260으로 알려져는 있다. 뭐가 맞는지는 모르겠다.\n","# https://github.com/pytorch/vision/blob/98c58158d1bc09e6fab31d3bf1af36e8d1752a89/torchvision/models/efficientnet.py#L516\n","\n","def efficientnet_b3(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=1.4, width_mult=1.2, resize_size=320, crop_size=300, drop_p=0.3, **kwargs)\n","\n","def efficientnet_b4(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=1.8, width_mult=1.4, resize_size=384, crop_size=380, drop_p=0.4, **kwargs)\n","\n","def efficientnet_b5(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=2.2, width_mult=1.6, resize_size=456, crop_size=456, drop_p=0.4, **kwargs)\n","\n","def efficientnet_b6(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=2.6, width_mult=1.8, resize_size=528, crop_size=528, drop_p=0.5, **kwargs)\n","\n","def efficientnet_b7(num_classes=1000, **kwargs):\n","    return EfficientNet(num_classes=num_classes, depth_mult=3.1, width_mult=2.0, resize_size=600, crop_size=600, drop_p=0.5, **kwargs)"],"metadata":{"id":"wXYVFkHQ4HE3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = efficientnet_b5()\n","# print(model)\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,456,456), device='cpu')"],"metadata":{"id":"ox9I3Isn4HHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_DS = datasets.CIFAR10(root = '/content/drive/MyDrive/Colab Notebooks/data', train=False, download=True, transform=model.transforms) # model.transforms 가 여기서 쓰인다!\n","test_DL = torch.utils.data.DataLoader(test_DS, batch_size = 2)\n","\n","x_batch, _ = next(iter(test_DL))\n","\n","print(model(x_batch).shape)\n","model.train()\n","print(model(x_batch))\n","print(model(x_batch)) # stochastic depth, dropout 때문에 계속 바뀜\n","model.eval()\n","print(model(x_batch))\n","print(model(x_batch)) # 고정!"],"metadata":{"id":"pVJF6E2F4HJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.DataFrame(index=['B0', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7'], columns=['depth_mult', 'width_mult', 'resolution'])\n","\n","alpha = 1.2 # depth factor: d = alpha**phi\n","beta = 1.1 # width factor: w = beta**phi\n","gamma = 1.15 # resolution factor: r = gamma**phi\n","\n","phi = [0, 0.5, 1.08, 2.035, 3.5, 4.5, 5.5, 6.29]\n","\n","for i, val in enumerate(phi):\n","    df.loc['B'+str(i), 'depth_mult'] = round(alpha**val, 1)\n","    df.loc['B'+str(i), 'width_mult'] = round(beta**val, 1)\n","    df.loc['B'+str(i), 'resolution'] = round(224*gamma**val)\n","    df.loc['B'+str(i), 'phi'] = phi[i]\n","\n","df\n","# d=1.0, w=1.0, r=224\n","# d=1.1, w=1.0, r=240\n","# d=1.2, w=1.1, r=260\n","# d=1.4, w=1.2, r=300\n","# d=1.8, w=1.4, r=380\n","# d=2.2, w=1.6, r=456\n","# d=2.6, w=1.8, r=528\n","# d=3.1, w=2.0, r=600"],"metadata":{"id":"LK-kly0B4NWB"},"execution_count":null,"outputs":[]}]}