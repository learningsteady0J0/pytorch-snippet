{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3nRK57d2WPbiwxFE8NW92"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fBz3s1Eejtes"},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"code","source":["class BasicConv2d(nn.Module):\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super().__init__()\n","        self.conv_block = nn.Sequential(nn.Conv2d(in_channels, out_channels, bias=False, **kwargs),\n","                                        nn.BatchNorm2d(out_channels, eps=0.001),\n","                                        nn.ReLU())\n","    def forward(self, x):\n","        x = self.conv_block(x)\n","        return x\n","\n","class Inception_Stem(nn.Module):\n","    # Figure 3.\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(BasicConv2d(3, 32, kernel_size=3, stride=2),\n","                                   BasicConv2d(32, 32, kernel_size=3),\n","                                   BasicConv2d(32, 64, kernel_size=3, padding=1))\n","        self.branch3x3_pool = nn.MaxPool2d(3, stride=2)\n","        self.branch3x3_conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n","\n","        self.branch7x7a = nn.Sequential(BasicConv2d(160, 64, kernel_size=1),\n","                                        BasicConv2d(64, 96, kernel_size=3))\n","        self.branch7x7b = nn.Sequential(BasicConv2d(160, 64, kernel_size=1),\n","                                        BasicConv2d(64, 64, kernel_size=(7, 1), padding=(3, 0)),\n","                                        BasicConv2d(64, 64, kernel_size=(1, 7), padding=(0, 3)),\n","                                        BasicConv2d(64, 96, kernel_size=3))\n","\n","        self.branchpoola = BasicConv2d(192, 192, kernel_size=3, stride=2)\n","        self.branchpoolb = nn.MaxPool2d(3, stride=2)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = [self.branch3x3_pool(x),\n","             self.branch3x3_conv(x)]\n","        x = torch.cat(x, 1)\n","\n","        x = [self.branch7x7a(x),\n","             self.branch7x7b(x)]\n","        x = torch.cat(x, 1)\n","\n","        x = [self.branchpoola(x),\n","             self.branchpoolb(x)]\n","        x = torch.cat(x, 1)\n","        return x\n","\n","class InceptionA(nn.Module):\n","    # Figure 4.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branchpool = nn.Sequential(nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n","                                        BasicConv2d(input_channels, 96, kernel_size=1))\n","\n","        self.branch1x1 = BasicConv2d(input_channels, 96, kernel_size=1)\n","\n","        self.branch3x3 = nn.Sequential(BasicConv2d(input_channels, 64, kernel_size=1),\n","                                       BasicConv2d(64, 96, kernel_size=3, padding=1))\n","\n","        self.branch3x3dbl = nn.Sequential(BasicConv2d(input_channels, 64, kernel_size=1),\n","                                            BasicConv2d(64, 96, kernel_size=3, padding=1),\n","                                            BasicConv2d(96, 96, kernel_size=3, padding=1))\n","\n","    def forward(self, x):\n","        x = [self.branchpool(x), self.branch1x1(x), self.branch3x3(x), self.branch3x3dbl(x)]\n","        return torch.cat(x, 1)\n","\n","class ReductionA(nn.Module):\n","    # Figure 7.\n","    # The k, l, m, n numbers represent filter bank sizes which can be looked up in Table 1.\n","    def __init__(self, input_channels, k, l, m, n):\n","        super().__init__()\n","\n","        self.branchpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.branch3x3 = BasicConv2d(input_channels, n, kernel_size=3, stride=2)\n","        self.branch3x3dbl = nn.Sequential(BasicConv2d(input_channels, k, kernel_size=1),\n","                                          BasicConv2d(k, l, kernel_size=3, padding=1),\n","                                          BasicConv2d(l, m, kernel_size=3, stride=2))\n","\n","    def forward(self, x):\n","        x = [self.branchpool(x), self.branch3x3(x), self.branch3x3dbl(x)]\n","        return torch.cat(x, 1)\n","\n","class InceptionB(nn.Module):\n","\n","    # Figure 5.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branchpool = nn.Sequential(\n","            nn.AvgPool2d(3, stride=1, padding=1),\n","            BasicConv2d(input_channels, 128, kernel_size=1))\n","\n","        self.branch1x1 = BasicConv2d(input_channels, 384, kernel_size=1)\n","\n","        self.branch7x7 = nn.Sequential(\n","            BasicConv2d(input_channels, 192, kernel_size=1),\n","            BasicConv2d(192, 224, kernel_size=(1, 7), padding=(0, 3)),\n","            BasicConv2d(224, 256, kernel_size=(7, 1), padding=(3, 0))) # 논문은 여기도 1x7로 되어있음. 하지만 오류일 것으로 추정\n","\n","        self.branch7x7dbl = nn.Sequential(\n","            BasicConv2d(input_channels, 192, kernel_size=1),\n","            BasicConv2d(192, 192, kernel_size=(1, 7), padding=(0, 3)),\n","            BasicConv2d(192, 224, kernel_size=(7, 1), padding=(3, 0)),\n","            BasicConv2d(224, 224, kernel_size=(1, 7), padding=(0, 3)),\n","            BasicConv2d(224, 256, kernel_size=(7, 1), padding=(3, 0)))\n","\n","    def forward(self, x):\n","        x = [self.branchpool(x), self.branch1x1(x), self.branch7x7(x), self.branch7x7dbl(x)]\n","        return torch.cat(x, 1)\n","\n","class ReductionB(nn.Module):\n","    # Figure 8.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branchpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","\n","        self.branch3x3 = nn.Sequential(\n","            BasicConv2d(input_channels, 192, kernel_size=1),\n","            BasicConv2d(192, 192, kernel_size=3, stride=2))\n","\n","        self.branch7x7 = nn.Sequential(\n","            BasicConv2d(input_channels, 256, kernel_size=1),\n","            BasicConv2d(256, 256, kernel_size=(1, 7), padding=(0, 3)),\n","            BasicConv2d(256, 320, kernel_size=(7, 1), padding=(3, 0)),\n","            BasicConv2d(320, 320, kernel_size=3, stride=2))\n","\n","    def forward(self, x):\n","        x = [self.branchpool(x), self.branch3x3(x), self.branch7x7(x)]\n","        return torch.cat(x, 1)\n","\n","class InceptionC(nn.Module):\n","    # Figure 6.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branchpool = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=3, stride=1, padding=1),\n","            BasicConv2d(input_channels, 256, kernel_size=1))\n","\n","        self.branch1x1 = BasicConv2d(input_channels, 256, kernel_size=1)\n","\n","        self.branch3x3 = BasicConv2d(input_channels, 384, kernel_size=1)\n","        self.branch3x3a = BasicConv2d(384, 256, kernel_size=(1, 3), padding=(0, 1))\n","        self.branch3x3b = BasicConv2d(384, 256, kernel_size=(3, 1), padding=(1, 0))\n","\n","        self.branch3x3dbl = nn.Sequential(\n","            BasicConv2d(input_channels, 384, kernel_size=1),\n","            BasicConv2d(384, 448, kernel_size=(1, 3), padding=(0, 1)),\n","            BasicConv2d(448, 512, kernel_size=(3, 1), padding=(1, 0)))\n","        self.branch3x3dbla = BasicConv2d(512, 256, kernel_size=(3, 1), padding=(1, 0))\n","        self.branch3x3dblb = BasicConv2d(512, 256, kernel_size=(1, 3), padding=(0, 1))\n","\n","    def forward(self, x):\n","        branchpool = self.branchpool(x)\n","\n","        branch1x1 = self.branch1x1(x)\n","\n","        branch3x3 = self.branch3x3(x)\n","        branch3x3 = [self.branch3x3a(branch3x3),\n","                     self.branch3x3b(branch3x3)]\n","        branch3x3 = torch.cat(branch3x3, 1)\n","\n","        branch3x3dbl = self.branch3x3dbl(x)\n","        branch3x3dbl = [self.branch3x3dbla(branch3x3dbl),\n","                        self.branch3x3dblb(branch3x3dbl)]\n","        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n","\n","        outputs = [branch1x1, branch3x3, branch3x3dbl, branchpool]\n","\n","        return torch.cat(outputs, 1)\n","\n","class InceptionV4(nn.Module):\n","    # Figure 9.\n","    def __init__(self, A, B, C, k=192, l=224, m=256, n=384, class_nums=1000):\n","        super().__init__()\n","        self.stem = Inception_Stem()\n","        self.inception_a = nn.Sequential(*[InceptionA(384) for _ in range(A)])\n","        self.reduction_a = ReductionA(384, k, l, m, n)\n","        self.inception_b = nn.Sequential(*[InceptionB(1024) for _ in range(B)])\n","        self.reduction_b = ReductionB(1024)\n","        self.inception_c = nn.Sequential(*[InceptionC(1536) for _ in range(C)])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n","        self.dropout = nn.Dropout2d(0.2)\n","        self.linear = nn.Linear(1536, class_nums)\n","\n","    def forward(self, x):\n","        x = self.stem(x)\n","        x = self.inception_a(x)\n","        x = self.reduction_a(x)\n","        x = self.inception_b(x)\n","        x = self.reduction_b(x)\n","        x = self.inception_c(x)\n","        x = self.avgpool(x)\n","        x = self.dropout(x)\n","        x = torch.flatten(x,1)\n","        x = self.linear(x)\n","        return x"],"metadata":{"id":"CdR4uzKBj6xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = InceptionV4(4, 7, 3)\n","# print(model)\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,299,299), device='cpu')"],"metadata":{"id":"sEIVIMKEj6z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = model(torch.randn(2,3,299,299))\n","print(x.shape)"],"metadata":{"id":"8cPjl2Mnj63F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class InceptionResNetA(nn.Module):\n","    # Figure 16.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branch1x1 = BasicConv2d(input_channels, 32, kernel_size=1)\n","        self.branch3x3 = nn.Sequential(\n","            BasicConv2d(input_channels, 32, kernel_size=1),\n","            BasicConv2d(32, 32, kernel_size=3, padding=1))\n","        self.branch3x3dbl = nn.Sequential(\n","            BasicConv2d(input_channels, 32, kernel_size=1),\n","            BasicConv2d(32, 48, kernel_size=3, padding=1),\n","            BasicConv2d(48, 64, kernel_size=3, padding=1))\n","        self.reduction1x1 = nn.Conv2d(128, 384, kernel_size=1)\n","        self.bn = nn.BatchNorm2d(384)\n","\n","        self.shortcut = nn.Sequential(nn.Conv2d(input_channels, 384, kernel_size=1),\n","                                      nn.BatchNorm2d(384))\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        residual = [self.branch1x1(x),\n","                    self.branch3x3(x),\n","                    self.branch3x3dbl(x)]\n","        residual = torch.cat(residual, 1)\n","        residual = self.reduction1x1(residual) * 0.1 # Figure 20. 에 맞게 이 모듈에만 0.1이 없길래 추가함\n","        residual = self.bn(residual)\n","\n","        shortcut = self.shortcut(x)\n","\n","        output = self.relu(residual + shortcut)\n","        return output\n","\n","class InceptionResNetReductionA(nn.Module):\n","    # Figure 7.\n","    # The k, l, m, n numbers represent filter bank sizes which can be looked up in Table 1.\n","    def __init__(self, input_channels, k, l, m, n):\n","        super().__init__()\n","\n","        self.branchpool = nn.MaxPool2d(kernel_size=3, stride=2)\n","        self.branch3x3 = BasicConv2d(input_channels, n, kernel_size=3, stride=2)\n","        self.branch3x3dbl = nn.Sequential(BasicConv2d(input_channels, k, kernel_size=1),\n","                                          BasicConv2d(k, l, kernel_size=3, padding=1),\n","                                          BasicConv2d(l, m, kernel_size=3, stride=2))\n","\n","    def forward(self, x):\n","        x = [self.branchpool(x), self.branch3x3(x), self.branch3x3dbl(x)]\n","        return torch.cat(x, 1)\n","\n","class InceptionResNetB(nn.Module):\n","    # Figure 17.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branch1x1 = BasicConv2d(input_channels, 192, kernel_size=1)\n","        self.branch7x7 = nn.Sequential(\n","            BasicConv2d(input_channels, 128, kernel_size=1),\n","            BasicConv2d(128, 160, kernel_size=(1, 7), padding=(0, 3)),\n","            BasicConv2d(160, 192, kernel_size=(7, 1), padding=(3, 0)))\n","        self.reduction1x1 = nn.Conv2d(384, 1154, kernel_size=1)\n","        self.bn = nn.BatchNorm2d(1154)\n","\n","        self.shortcut = nn.Sequential(nn.Conv2d(input_channels, 1154, kernel_size=1),\n","                                      nn.BatchNorm2d(1154))\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        residual = [self.branch1x1(x),\n","                    self.branch7x7(x)]\n","        residual = torch.cat(residual, 1)\n","        residual = self.reduction1x1(residual) * 0.1 # Figure 20.\n","        residual = self.bn(residual)\n","\n","        shortcut = self.shortcut(x)\n","\n","        output = self.relu(residual + shortcut)\n","        return output\n","\n","class InceptionResNetReductionB(nn.Module):\n","    # Figure 18.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branchpool = nn.MaxPool2d(3, stride=2)\n","\n","        self.branch3x3a = nn.Sequential(\n","            BasicConv2d(input_channels, 256, kernel_size=1),\n","            BasicConv2d(256, 384, kernel_size=3, stride=2))\n","\n","        self.branch3x3b = nn.Sequential(\n","            BasicConv2d(input_channels, 256, kernel_size=1),\n","            BasicConv2d(256, 288, kernel_size=3, stride=2))\n","\n","        self.branch3x3dbl = nn.Sequential(\n","            BasicConv2d(input_channels, 256, kernel_size=1),\n","            BasicConv2d(256, 288, kernel_size=3, padding=1),\n","            BasicConv2d(288, 320, kernel_size=3, stride=2))\n","\n","    def forward(self, x):\n","        x = [self.branch3x3a(x), self.branch3x3b(x), self.branch3x3dbl(x), self.branchpool(x)]\n","        return torch.cat(x, 1)\n","\n","class InceptionResNetC(nn.Module):\n","    # Figure 19.\n","    def __init__(self, input_channels):\n","        super().__init__()\n","\n","        self.branch1x1 = BasicConv2d(input_channels, 192, kernel_size=1)\n","        self.branch3x3 = nn.Sequential(\n","            BasicConv2d(input_channels, 192, kernel_size=1),\n","            BasicConv2d(192, 224, kernel_size=(1, 3), padding=(0, 1)),\n","            BasicConv2d(224, 256, kernel_size=(3, 1), padding=(1, 0)))\n","        self.reduction1x1 = nn.Conv2d(448, 2048, kernel_size=1)\n","        self.bn = nn.BatchNorm2d(2048)\n","\n","        self.shortcut = nn.Sequential(nn.Conv2d(input_channels, 2048, kernel_size=1),\n","                                      nn.BatchNorm2d(2048))\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        residual = [self.branch1x1(x),\n","                    self.branch3x3(x)]\n","        residual = torch.cat(residual, 1)\n","        residual = self.reduction1x1(residual) * 0.1 # Figure 20.\n","        residual = self.bn(residual)\n","\n","        shortcut = self.shortcut(x)\n","\n","        output = self.relu(residual + shortcut)\n","        return output\n","\n","class InceptionResNetV2(nn.Module):\n","    # Figure 15.\n","    def __init__(self, A, B, C, k=256, l=256, m=384, n=384, class_nums=1000):\n","        super().__init__()\n","        self.stem = Inception_Stem()\n","        self.inception_resnet_a = nn.Sequential(*[InceptionResNetA(384) for _ in range(A)])\n","        self.reduction_a = InceptionResNetReductionA(384, k, l, m, n)\n","        self.inception_resnet_b = nn.Sequential(InceptionResNetB(1152),\n","                                                *[InceptionResNetB(1154) for _ in range(B-1)])\n","        self.reduction_b = InceptionResNetReductionB(1154)\n","        self.inception_resnet_c = nn.Sequential(InceptionResNetC(2146),\n","                                                *[InceptionResNetC(2048) for _ in range(C-1)])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        # Dropout (keep 0.8)\n","        self.dropout = nn.Dropout2d(0.2)\n","        self.linear = nn.Linear(2048, class_nums)\n","\n","    def forward(self, x):\n","        x = self.stem(x)\n","        x = self.inception_resnet_a(x)\n","        x = self.reduction_a(x)\n","        x = self.inception_resnet_b(x)\n","        x = self.reduction_b(x)\n","        x = self.inception_resnet_c(x)\n","        x = self.avgpool(x)\n","        x = self.dropout(x)\n","        x = torch.flatten(x,1)\n","        x = self.linear(x)\n","        return x"],"metadata":{"id":"eCLdIgCkkNsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = InceptionResNetV2(5, 10, 5)\n","# print(model)\n","summary(model, input_size=(2,3,299,299), device='cpu')"],"metadata":{"id":"iqJVVTRwkNun"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.randn(2,3,299,299)\n","print(model(x).shape)"],"metadata":{"id":"pjvu0T55kRTI"},"execution_count":null,"outputs":[]}]}