{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTD2xoma+IQvTi7eed0ekH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"f7xY_E7ekBVv"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["class Bottleneck(nn.Module):\n","    def __init__(self, in_channels, k):\n","        super().__init__()\n","\n","        self.residual = nn.Sequential(nn.BatchNorm2d(in_channels),\n","                                      nn.ReLU(inplace=True),\n","                                      nn.Conv2d(in_channels, 4*k, kernel_size=1, bias=False),\n","                                      nn.BatchNorm2d(4*k),\n","                                      nn.ReLU(inplace=True),\n","                                      nn.Conv2d(4*k, k, kernel_size=3, padding=1, bias=False))\n","\n","    def forward(self, x):\n","        return torch.cat([x, self.residual(x)], 1) # x가 바로 직전 채널 뿐만 아니라 그 전것도 모두 가지고 있음\n","\n","class Transition(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.transition = nn.Sequential(nn.BatchNorm2d(in_channels),\n","                                        nn.ReLU(inplace=True),\n","                                        nn.Conv2d(in_channels, out_channels, 1, bias=False),\n","                                        nn.AvgPool2d(2))\n","\n","    def forward(self, x):\n","        return self.transition(x)\n","\n","#DesneNet-BC\n","#B stands for bottleneck layer(BN-RELU-CONV(1x1)-BN-RELU-CONV(3x3))\n","#C stands for compression factor(0< theta ≤1)\n","class DenseNet(nn.Module):\n","    def __init__(self, num_block_list, growth_rate, reduction=0.5, num_class=100):\n","        super().__init__()\n","        self.k = growth_rate\n","\n","        inner_channels = 2 * self.k\n","\n","        self.conv1 = nn.Sequential(nn.Conv2d(3, inner_channels, kernel_size=7, stride=2, padding=3, bias=False),\n","                                   nn.BatchNorm2d(inner_channels),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n","\n","        layers = []\n","        for num_blocks in num_block_list[:-1]:\n","            layers += [self.make_dense_block(inner_channels, num_blocks)]\n","            inner_channels +=  num_blocks * self.k\n","\n","            out_channels = int(reduction * inner_channels)\n","            layers += [Transition(inner_channels, out_channels)]\n","            inner_channels = out_channels\n","\n","        layers += [self.make_dense_block(inner_channels, num_block_list[-1])]\n","        inner_channels += num_block_list[-1] * self.k\n","\n","        layers += [nn.BatchNorm2d(inner_channels)]\n","        layers += [nn.ReLU(inplace=True)]\n","        self.features = nn.Sequential(*layers)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.linear = nn.Linear(inner_channels, num_class)\n","\n","        # Official init from torch repo.\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        output = self.conv1(x)\n","        output = self.features(output)\n","        output = self.avgpool(output)\n","        output = torch.flatten(output, start_dim=1)\n","        output = self.linear(output)\n","        return output\n","\n","    def make_dense_block(self, in_channels, nblocks):\n","        dense_block = []\n","        for _ in range(nblocks):\n","            dense_block += [ Bottleneck(in_channels, self.k) ]\n","            in_channels += self.k\n","        return nn.Sequential(*dense_block)"],"metadata":{"id":"Hbmi6bjfkDTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def densenet121(**kwargs):\n","    return DenseNet([6,12,24,16], growth_rate=32, **kwargs)\n","\n","def densenet169(**kwargs):\n","    return DenseNet([6,12,32,32], growth_rate=32, **kwargs)\n","\n","def densenet201(**kwargs):\n","    return DenseNet([6,12,48,32], growth_rate=32, **kwargs)\n","\n","def densenet264(**kwargs):\n","    return DenseNet([6,12,64,48], growth_rate=32, **kwargs)"],"metadata":{"id":"4DWBxO_VkEU9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = densenet264()\n","# print(model)\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,224,224), device='cpu')"],"metadata":{"id":"8lTF1PVykEW5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.randn(2,3,224,224)\n","print(model(x).shape)"],"metadata":{"id":"_8L5YVZ1kIAV"},"execution_count":null,"outputs":[]}]}